# RAG Chatbot for Non-Communicable Diseases - Backend API

A production-ready FastAPI backend for a Retrieval-Augmented Generation (RAG) chatbot that provides information about non-communicable diseases using LangChain, ChromaDB, and Google Gemini.

## üèóÔ∏è Architecture

This is a **backend-only** repository designed to be consumed by any frontend application (React, Vue, Angular, etc.) via REST API.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Your Frontend  ‚îÇ  (Separate Repo)
‚îÇ   React/Vue/    ‚îÇ
‚îÇ   Angular/etc   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP REST API
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI Backend    ‚îÇ  ‚Üê This Repository
‚îÇ  (Port 8000)        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ RAG Pipeline ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ + LangChain  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇChroma ‚îÇ   ‚îÇ  Google    ‚îÇ
‚îÇVector ‚îÇ   ‚îÇ  Gemini    ‚îÇ
‚îÇ  DB   ‚îÇ   ‚îÇ    API     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚ú® Features

- üöÄ **FastAPI Backend** - High-performance REST API
- üìö **PDF Document Processing** - Automatic ingestion and chunking
- üîç **Vector Search** - ChromaDB for semantic similarity
- ü§ñ **Google Gemini Integration** - Powered by Google's LLM
- üìä **Source Attribution** - Track information sources
- üîÑ **Auto-reload** - Development mode with hot reload
- üìñ **Interactive Docs** - Swagger UI and ReDoc
- üåê **CORS Enabled** - Ready for frontend integration

## üìÅ Project Structure

```
RAG-Non-communicable-diseases/
‚îú‚îÄ‚îÄ app.py                  # FastAPI application
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py  # Document loading and chunking
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py    # ChromaDB vector database
‚îÇ   ‚îú‚îÄ‚îÄ chatbot.py         # RAG chatbot logic
‚îÇ   ‚îî‚îÄ‚îÄ setup.py           # Database initialization
‚îú‚îÄ‚îÄ data/                  # Your PDF documents
‚îú‚îÄ‚îÄ chroma_db/            # Vector database (auto-created)
‚îú‚îÄ‚îÄ setup_backend.bat     # Windows setup script
‚îú‚îÄ‚îÄ setup_backend.sh      # Linux/Mac setup script
‚îú‚îÄ‚îÄ start_backend.bat     # Windows start script
‚îú‚îÄ‚îÄ start_backend.sh      # Linux/Mac start script
‚îú‚îÄ‚îÄ test_backend.py       # API test script
‚îú‚îÄ‚îÄ .env.example         # Environment template
‚îú‚îÄ‚îÄ requirements.txt     # Dependencies
‚îú‚îÄ‚îÄ QUICK_START.md      # Quick reference
‚îî‚îÄ‚îÄ README.md           # This file
```

## üöÄ Quick Start

### Prerequisites
- Python 3.8 or higher
- Google API Key ([Get one here](https://makersuite.google.com/app/apikey))
- PDF documents about non-communicable diseases

### Installation

#### Windows

1. **Run setup:**
   ```bash
   setup_backend.bat
   ```

2. **Configure environment:**
   Edit `.env` file and add your API key:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   ```

3. **Add your documents:**
   Place PDF files in the `data/` folder

4. **Create vector database:**
   ```bash
   venv\Scripts\activate
   python -m src.setup
   ```

5. **Start the server:**
   ```bash
   start_backend.bat
   ```

#### Linux/Mac

1. **Run setup:**
   ```bash
   chmod +x setup_backend.sh start_backend.sh
   ./setup_backend.sh
   ```

2. **Configure environment:**
   Edit `.env` file and add your API key:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   ```

3. **Add your documents:**
   Place PDF files in the `data/` folder

4. **Create vector database:**
   ```bash
   source venv/bin/activate
   python -m src.setup
   ```

5. **Start the server:**
   ```bash
   ./start_backend.sh
   ```

### Access the API

- **API Server**: http://localhost:8000
- **Interactive Docs (Swagger)**: http://localhost:8000/docs
- **Alternative Docs (ReDoc)**: http://localhost:8000/redoc

---

## ÔøΩ Complete API Reference

### Authentication
Currently no authentication required. Add authentication middleware as needed for production.

### Request/Response Format
All requests and responses use JSON format with `Content-Type: application/json`.

### Endpoints Details

#### 1. Root - GET `/`
Basic API information endpoint.

**Response:**
```json
{
  "status": "ok",
  "message": "NCD RAG Chatbot API is running"
}
```

#### 2. Health Check - GET `/health`
Check backend and vector database status.

**Response (Healthy):**
```json
{
  "status": "healthy",
  "message": "Chatbot is ready"
}
```

**Response (Unhealthy):**
```json
{
  "status": "unhealthy",
  "message": "Vector store not initialized. Please run setup first."
}
```

#### 3. Chat - POST `/chat`
Main endpoint for asking questions.

**Request Body:**
```json
{
  "question": "string (required)",
  "return_sources": "boolean (optional, default: false)"
}
```

**Response:**
```json
{
  "answer": "string",
  "sources": [
    {
      "source": "filename.pdf",
      "content": "snippet of source text..."
    }
  ]
}
```

**Error Responses:**
- `400` - Invalid or empty question
- `500` - Processing error
- `503` - Vector store not initialized

**Example with cURL:**
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What are diabetes symptoms?",
    "return_sources": true
  }'
```

**Example with JavaScript:**
```javascript
const response = await fetch('http://localhost:8000/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    question: 'What are diabetes symptoms?',
    return_sources: true
  })
});
const data = await response.json();
console.log(data.answer);
data.sources?.forEach(s => console.log(`Source: ${s.source}`));
```

**Example with Python:**
```python
import requests

response = requests.post('http://localhost:8000/chat', json={
    'question': 'What are diabetes symptoms?',
    'return_sources': True
})

data = response.json()
print(f"Answer: {data['answer']}")
if data.get('sources'):
    for source in data['sources']:
        print(f"Source: {source['source']}")
```

### Interactive Documentation

FastAPI automatically generates interactive API documentation:

- **Swagger UI**: http://localhost:8000/docs
  - Test endpoints directly in browser
  - View request/response schemas
  - Try out API calls
  
- **ReDoc**: http://localhost:8000/redoc
  - Alternative documentation view
  - Better for reading and reference

---

## ÔøΩüîå API Endpoints

### POST `/chat`
Send a question and receive an AI-generated answer.

**Request:**
```json
{
  "question": "What are the symptoms of diabetes?",
  "return_sources": false
}
```

**Response:**
```json
{
  "answer": "Diabetes symptoms include increased thirst, frequent urination...",
  "sources": null
}
```

### GET `/health`
Check if the API is ready.

**Response:**
```json
{
  "status": "healthy",
  "message": "Chatbot is ready"
}
```

üìñ **Full API Documentation**: See sections below or visit http://localhost:8000/docs when server is running

---

## üíª Frontend Integration

This backend is designed to work with **any frontend framework**. Here are quick examples:

### React/Next.js Example

```jsx
const response = await fetch('http://localhost:8000/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    question: 'What causes high blood pressure?',
    return_sources: false
  })
});
const data = await response.json();
console.log(data.answer);
```

### Vue.js Example

```javascript
const response = await axios.post('http://localhost:8000/chat', {
  question: 'What causes high blood pressure?',
  return_sources: false
});
console.log(response.data.answer);
```

### Angular Example

```typescript
this.http.post('http://localhost:8000/chat', {
  question: 'What causes high blood pressure?',
  return_sources: false
}).subscribe(data => console.log(data.answer));
```

See examples above for integration with your frontend framework.

---

## üß™ Testing the API

### Using cURL

```bash
# Health check
curl http://localhost:8000/health

# Ask a question
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "What is diabetes?", "return_sources": true}'
```

### Using Python

```python
import requests

response = requests.post('http://localhost:8000/chat', json={
    'question': 'What are the symptoms of high blood pressure?',
    'return_sources': True
})
print(response.json()['answer'])
```

### Using Browser
Visit http://localhost:8000/docs for interactive Swagger UI

---

## üìö How It Works

1. **Document Ingestion**: PDF documents are loaded from the `data/` folder
2. **Text Chunking**: Documents are split into manageable chunks with overlap
3. **Embedding**: Text chunks are converted to vector embeddings
4. **Storage**: Embeddings are stored in ChromaDB vector database
5. **Query**: User question is embedded and similar chunks are retrieved
6. **Generation**: Google Gemini generates answer based on retrieved context

---

## ‚öôÔ∏è Configuration

Edit `.env` file to customize:

```env
# Required
GOOGLE_API_KEY=your_api_key_here

# Optional
MODEL_NAME=gemini-pro
MODEL_TEMPERATURE=0.7
BACKEND_PORT=8000
RETRIEVAL_K=4
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
```

---

## üêõ Troubleshooting

### Vector store not found
**Solution**: Run `python -m src.setup` to create the database

### CORS errors
**Solution**: Add your frontend URL to `CORS_ORIGINS` in `.env`

### Import errors
**Solution**: Ensure virtual environment is activated

### No response from API
**Solution**: Check if server is running on port 8000

---

## üì¶ Manual Installation

If you prefer manual setup:

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate
# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure .env
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY

# Create vector database
python -m src.setup

# Start server
python -m uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

---

## üöÄ Production Deployment

For production environments:

```bash
# Install gunicorn
pip install gunicorn

# Run with multiple workers
gunicorn backend.app:app \
  -w 4 \
  -k uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000
```

Consider using:
- **Docker** for containerization
- **Nginx** as reverse proxy
- **SSL/TLS** for HTTPS
- **Environment variables** for secrets

---

## üìÑ License

MIT License

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## üìû Support

For issues and questions:
- Open an issue on GitHub
- Check [backend/README.md](backend/README.md) for detailed API docs
- Review the API docs at http://localhost:8000/docs
- Check the QUICK_START.md for common solution
---

## üéØ Roadmap

- [ ] WebSocket support for streaming responses
- [ ] Multiple LLM provider support
- [ ] Conversation history
- [ ] User authentication
- [ ] Rate limiting
- [ ] Caching layer
- [ ] Docker compose setup

---

**Built with ‚ù§Ô∏è using FastAPI, LangChain, ChromaDB, and Google Gemini**
